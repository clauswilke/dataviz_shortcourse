---
title: "Visualizing Uncertainty and Trends"
author: "Claus O. Wilke"
date: "last updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: [default, "Wilke-slides-theme.css"]
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      slideNumberFormat: ''
      titleSlideClass: [center, middle]
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(comment = "")

library(tidyverse)
library(here)
library(colorspace)
library(cowplot)

hpi_trends <- read_csv(here("datasets", "hpi_trends.csv"))
```


## We all know how to visualize uncertainty, right?

---

background-image: url("dataviz/visualizing_uncertainty_files/figure-html/butterfat-bars-1.png")
background-position: left 50% top 65%
background-size: 50%

## We all know how to visualize uncertainty, right?

.absolute-bottom-right.tiny-font[
Milk butterfat contents by cattle breed. 
Source: Canadian Record of Performance for Purebred Dairy Cattle
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

background-image: url("dataviz/visualizing_uncertainty_files/figure-html/median-age-income-1.png")
background-position: left 50% top 65%
background-size: 50%

## We all know how to visualize uncertainty, right?

.absolute-bottom-right.tiny-font[
Income versus age for 67 counties in Pennsylvania. 
Source: 2015 Five-Year American Community Survey
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

background-image: url("uncertainty_files/blue-jays-static.png")
background-position: left 50% top 75%
background-size: 50%

## We all know how to visualize uncertainty, right?

.absolute-bottom-right.tiny-font[
Head length versus body mass for male blue jays. Data source: Keith Tarvin, Oberlin College
]

???

Figure redrawn after [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)


---

## Two problems

--

1. It's often not clear what the visualizations represent

--

2. Even if we know, we can have difficulty interpreting them

---


## 1. It's often not clear what the visualizations represent

In particular, error bars can represent many different quantities

---

background-image: url("dataviz/visualizing_uncertainty_files/figure-html/cocoa-data-vs-CI-1.png")
background-position: left 50% top 65%
background-size: 80%

## Error bars can represent many different quantities

.absolute-bottom-right.tiny-font[
Chocolate bar ratings. Source: Manhattan Chocolate Society
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

## 2. We can have difficulty interpreting the visualizations


.absolute-bottom-right.tiny-font[Lace Padilla, Matthew Kay, and Jessica Hullman (2022): [Uncertainty Visualization](
https://osf.io/preprints/psyarxiv/ebd6r)
]


--

- People are not good at reasoning about probabilities

--

- People will substitute uncertainty with simpler concepts  
(Deterministic Construal Error)


---

## 2. We can have difficulty interpreting the visualizations

- People are not good at reasoning about probabilities

- People will substitute uncertainty with simpler concepts  
(Deterministic Construal Error)

- People will interpret ranges as boundaries

.absolute-bottom-right.tiny-font[Lace Padilla, Matthew Kay, and Jessica Hullman (2022): [Uncertainty Visualization](
https://osf.io/preprints/psyarxiv/ebd6r)
]


---

background-image: url("uncertainty_files/confidence-visualizations-3.png")
background-position: left 50% top 65%
background-size: 60%

## Uncertainty shown as 95% CI error bars with caps

.absolute-bottom-right.tiny-font[
Relative rankings compared to US chocolate bars. Source: Manhattan Chocolate Society
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

background-image: url("uncertainty_files/confidence-visualizations-3.png")
background-position: left 50% top 65%
background-size: 60%

## Uncertainty shown as 95% CI error bars with caps

Determinstic Construal Error: Error bars are interpreted as min/max values

.absolute-bottom-right.tiny-font[
Relative rankings compared to US chocolate bars. Source: Manhattan Chocolate Society
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)


---

background-image: url("uncertainty_files/confidence-visualizations-3.png")
background-position: left 50% top 65%
background-size: 60%

## Uncertainty shown as 95% CI error bars with caps

Categorical thinking: Areas outside and inside the error bars are categorically different

.absolute-bottom-right.tiny-font[
Relative rankings compared to US chocolate bars. Source: Manhattan Chocolate Society
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)


---

background-image: url("uncertainty_files/confidence-visualizations-4.png")
background-position: left 50% top 65%
background-size: 60%

## Uncertainty shown as 95% CI error bars without caps

You can remove caps to make the boundary visually less severe

.absolute-bottom-right.tiny-font[
Relative rankings compared to US chocolate bars. Source: Manhattan Chocolate Society
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

background-image: url("uncertainty_files/confidence-visualizations-2.png")
background-position: left 50% top 65%
background-size: 60%

## Uncertainty shown as graded error bars

You can show multiple confidence levels to de-emphasize existence of boundary

.absolute-bottom-right.tiny-font[
Relative rankings compared to US chocolate bars. Source: Manhattan Chocolate Society
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)


---

background-image: url("uncertainty_files/confidence-visualizations-5.png")
background-position: left 50% top 65%
background-size: 60%

## Uncertainty shown as confidence strips

You can use faded strips (but hard to read/interpret)

.absolute-bottom-right.tiny-font[
Relative rankings compared to US chocolate bars. Source: Manhattan Chocolate Society
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

background-image: url("uncertainty_files/confidence-visualizations-6.png")
background-position: left 50% top 75%
background-size: 60%

## Uncertainty shown as distributions

You can show actual distributions  
Popular in Bayesian inference, but still difficult to interpret

.absolute-bottom-right.tiny-font[
Relative rankings compared to US chocolate bars. Source: Manhattan Chocolate Society
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

## Hypothetical Outcome Plots

What would you experience comparing two random chocolate bars?

.absolute-bottom-right.tiny-font[
[Hullman et al., PLOS ONE 2015](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142444)
]

---

background-image: url("dataviz/visualizing_uncertainty_files/figure-html/chocolate-HOP-animated-1.gif")
background-position: left 50% top 70%
background-size: 60%

## Hypothetical Outcome Plots

What would you experience comparing two random chocolate bars?

.absolute-bottom-right.tiny-font[
[Hullman et al., PLOS ONE 2015](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142444)
]

---

## Use frequency framing to reason about probabilities

.center[
```{r freq-waffle, out.width = "40%", fig.width = 4.5, fig.asp = 1, echo = FALSE, dev = "svg"}
g <- expand.grid(x = 1:10, y = 1:10)

set.seed(84520)
data <- data.frame(ratio = c(0.99, 0.9, 0.7, 0.3, 0.1)) %>%
  mutate(
    out = purrr::map(
      ratio,
      ~g %>% mutate(
        value = {
          n <- n()
          i <- round(n*.x)
          sample(c(rep("W", i), rep("L", n - i)), n)
        }
      )
    )
  ) %>%
  unnest(cols = out) %>%
  mutate(
    label = paste0(round(100*(1-ratio)), "% chance")
  )

data %>% filter(ratio == .99) %>%
  ggplot(aes(x, y, fill = value)) +
  geom_tile(color = "white", linewidth = 2) +
  coord_fixed(expand = FALSE, clip = "off") +
  scale_x_continuous(name = NULL, breaks = NULL) +
  scale_y_continuous(name = NULL, breaks = NULL) +
  scale_fill_manual(
    name = NULL,
    breaks = c("W", "L"),
    labels = c("loss   ", "win"),
    values = c(
      "L" = desaturate(darken("#0072B2", .4), .5),
      "W" = desaturate(lighten("#0072B2", .7), .5)
    ),
    guide = guide_legend(override.aes = list(size = 0))
  ) +
  facet_wrap(~label) +
  theme_minimal_grid(20) +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.justification = "right",
    legend.box.spacing = unit(12, "pt"),
    legend.spacing.x = unit(3, "pt"),
    legend.key.size = unit(18, "pt")
  )
```
]

---

## Use frequency framing to reason about probabilities

.center[
```{r freq-waffle2, out.width = "40%", fig.width = 4.5, fig.asp = 1, echo = FALSE, dev = "svg"}
data %>% filter(ratio == .9) %>%
  ggplot(aes(x, y, fill = value)) +
  geom_tile(color = "white", linewidth = 2) +
  coord_fixed(expand = FALSE, clip = "off") +
  scale_x_continuous(name = NULL, breaks = NULL) +
  scale_y_continuous(name = NULL, breaks = NULL) +
  scale_fill_manual(
    name = NULL,
    breaks = c("W", "L"),
    labels = c("loss   ", "win"),
    values = c(
      "L" = desaturate(darken("#0072B2", .4), .5),
      "W" = desaturate(lighten("#0072B2", .7), .5)
    ),
    guide = guide_legend(override.aes = list(size = 0))
  ) +
  facet_wrap(~label) +
  theme_minimal_grid(20) +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.justification = "right",
    legend.box.spacing = unit(12, "pt"),
    legend.spacing.x = unit(3, "pt"),
    legend.key.size = unit(18, "pt")
  )
```
]

---

## Use frequency framing to reason about probabilities

.center[
```{r freq-waffle3, out.width = "40%", fig.width = 4.5, fig.asp = 1, echo = FALSE, dev = "svg"}
data %>% filter(ratio == .7) %>%
  ggplot(aes(x, y, fill = value)) +
  geom_tile(color = "white", linewidth = 2) +
  coord_fixed(expand = FALSE, clip = "off") +
  scale_x_continuous(name = NULL, breaks = NULL) +
  scale_y_continuous(name = NULL, breaks = NULL) +
  scale_fill_manual(
    name = NULL,
    breaks = c("W", "L"),
    labels = c("loss   ", "win"),
    values = c(
      "L" = desaturate(darken("#0072B2", .4), .5),
      "W" = desaturate(lighten("#0072B2", .7), .5)
    ),
    guide = guide_legend(override.aes = list(size = 0))
  ) +
  facet_wrap(~label) +
  theme_minimal_grid(20) +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.justification = "right",
    legend.box.spacing = unit(12, "pt"),
    legend.spacing.x = unit(3, "pt"),
    legend.key.size = unit(18, "pt")
  )
```
]

---

## Use frequency framing to reason about probabilities

.center[
```{r freq-waffle4, out.width = "40%", fig.width = 4.5, fig.asp = 1, echo = FALSE, dev = "svg"}
data %>% filter(ratio == .3) %>%
  ggplot(aes(x, y, fill = value)) +
  geom_tile(color = "white", linewidth = 2) +
  coord_fixed(expand = FALSE, clip = "off") +
  scale_x_continuous(name = NULL, breaks = NULL) +
  scale_y_continuous(name = NULL, breaks = NULL) +
  scale_fill_manual(
    name = NULL,
    breaks = c("W", "L"),
    labels = c("loss   ", "win"),
    values = c(
      "L" = desaturate(darken("#0072B2", .4), .5),
      "W" = desaturate(lighten("#0072B2", .7), .5)
    ),
    guide = guide_legend(override.aes = list(size = 0))
  ) +
  facet_wrap(~label) +
  theme_minimal_grid(20) +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.justification = "right",
    legend.box.spacing = unit(12, "pt"),
    legend.spacing.x = unit(3, "pt"),
    legend.key.size = unit(18, "pt")
  )
```
]

---

## Use frequency framing to reason about probabilities

.center[
```{r freq-waffle5, out.width = "40%", fig.width = 4.5, fig.asp = 1, echo = FALSE, dev = "svg"}
data %>% filter(ratio == .1) %>%
  ggplot(aes(x, y, fill = value)) +
  geom_tile(color = "white", linewidth = 2) +
  coord_fixed(expand = FALSE, clip = "off") +
  scale_x_continuous(name = NULL, breaks = NULL) +
  scale_y_continuous(name = NULL, breaks = NULL) +
  scale_fill_manual(
    name = NULL,
    breaks = c("W", "L"),
    labels = c("loss   ", "win"),
    values = c(
      "L" = desaturate(darken("#0072B2", .4), .5),
      "W" = desaturate(lighten("#0072B2", .7), .5)
    ),
    guide = guide_legend(override.aes = list(size = 0))
  ) +
  facet_wrap(~label) +
  theme_minimal_grid(20) +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.justification = "right",
    legend.box.spacing = unit(12, "pt"),
    legend.spacing.x = unit(3, "pt"),
    legend.key.size = unit(18, "pt")
  )
```
]

---

background-image: url("uncertainty_files/blue-jays-static.png")
background-position: left 50% top 75%
background-size: 50%


## Let's consider uncertainty of trend lines

.move-up-1em[
What does the confidence band show?
]

.absolute-bottom-right.tiny-font[
Head length versus body mass for male blue jays. Data source: Keith Tarvin, Oberlin College
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

background-image: url("uncertainty_files/blue-jays-HOP.gif")
background-position: left 50% top 75%
background-size: 50%

## Let's consider uncertainty of trend lines

.move-up-1em[
Both the intercept and the slope have uncertainty
]

.absolute-bottom-right.tiny-font[
Head length versus body mass for male blue jays. Data source: Keith Tarvin, Oberlin College
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

background-image: url("dataviz/visualizing_uncertainty_files/figure-html/mpg-uncertain-1.png")
background-position: left 50% top 65%
background-size: 80%

## It gets even more confusing for non-linear trend lines

.move-up-1em[
Individual posterior samples tend to be more wiggly than the mean
]

.absolute-bottom-right.tiny-font[
Fuel efficiency versus displacement, for 32 cars (1973–74 models). Source: Motor Trend, 1974.
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---

background-image: url("dataviz/visualizing_uncertainty_files/figure-html/mpg-uncertain-HOP-static-1.png")
background-position: left 50% top 77%
background-size: 75%

## It gets even more confusing for non-linear trend lines

.move-up-1em[
Individual posterior samples tend to be more wiggly than the mean
]

.absolute-bottom-right.tiny-font[
Fuel efficiency versus displacement, for 32 cars (1973–74 models). Source: Motor Trend, 1974.
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)

---


background-image: url("dataviz/visualizing_uncertainty_files/figure-html/mpg-uncertain-HOP-animated-1.gif")
background-position: left 50% top 70%
background-size: 50%

## Hypothetical Outcome Plots help develop intuition

.absolute-bottom-right.tiny-font[
Fuel efficiency versus displacement, for 32 cars (1973–74 models). Source: Motor Trend, 1974.
]

???

Figure from [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)




---

## Detrending: Removing the underlying trend

.center[
```{r hpi-no-trendline, echo = FALSE, warning = FALSE, out.width = "55%", fig.width = 6, fig.asp = 0.618, dev = "svg"}

hpi_trends %>%
  filter(state %in% c("California", "Nevada", "West Virginia", "Texas")) %>%
  ggplot(aes(date, hpi)) +
  geom_line(color = "#0072B2", linewidth = 0.75) +
  scale_x_date(name = NULL) +
  scale_y_log10(name = "House Price Index (Dec. 2000 = 100)") +
  facet_wrap(~state, scales = "free_x") +
  theme_minimal_hgrid() +
  theme(
    strip.text = element_text(size = 12),
    strip.background = element_rect(fill = "grey85"),
    axis.line.x = element_line(color = "grey50"),
    axis.ticks.x = element_line(color = "grey50"),
    axis.ticks.y = element_blank(),
    axis.text.y = element_text(margin = margin(0, 0, 0, 0))
  )

```
]

--

.small-font[
Did housing prices in California decline substantially from 1990 to 1998?
]

--

.small-font[
Did housing prices in West Virginia recover by 2017?
]

???

Figure redrawn after [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)


---

## Detrending: Removing the underlying trend

.center[
```{r hpi-trends, echo = FALSE, warning = FALSE, out.width = "55%", fig.width = 6, fig.asp = 0.618, dev = "svg"}

hpi_trends %>%
  filter(state %in% c("California", "Nevada", "West Virginia", "Texas")) %>%
  ggplot(aes(date, hpi)) +
  geom_line(aes(y = hpi_trend), color = "grey50", linewidth = 0.4) +
  geom_line(color = "#0072B2", linewidth = 0.75) +
  scale_x_date(name = NULL) +
  scale_y_log10(name = "House Price Index (Dec. 2000 = 100)") +
  facet_wrap(~state, scales = "free_x") +
  theme_minimal_hgrid() +
  theme(
    strip.text = element_text(size = 12),
    strip.background = element_rect(fill = "grey85"),
    axis.line.x = element_line(color = "grey50"),
    axis.ticks.x = element_line(color = "grey50"),
    axis.ticks.y = element_blank(),
    axis.text.y = element_text(margin = margin(0, 0, 0, 0))
  )

```
]

.small-font[
Did housing prices in California decline substantially from 1990 to 1998?
]

.small-font[
Did housing prices in West Virginia recover by 2017?
]

???

Figure redrawn after [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)


---

## Detrending: Removing the underlying trend

.center[
```{r hpi-detrended, echo = FALSE, warning = FALSE, out.width = "55%", fig.width = 6, fig.asp = 0.618, dev = "svg"}

hpi_trends %>%
  filter(state %in% c("California", "Nevada", "West Virginia", "Texas")) %>%
  ggplot(aes(date, hpi_detrended)) +
  geom_hline(yintercept = 1, color = "grey50", linewidth = 0.4) +
  geom_line(color = "#0072B2", linewidth = 0.75) +
  scale_x_date(name = NULL) +
  scale_y_log10(
    name = "House Price Index (detrended)",
    breaks = c(0.752, 1, 1.33, 1.77),
    labels = c("0.75", "1.00", "1.33", "1.77")
  ) +
  facet_wrap(~state, scales = "free_x") +
  theme_minimal_hgrid() +
  theme(
    strip.text = element_text(size = 12),
    strip.background = element_rect(fill = "grey85"),
    axis.line.x = element_line(color = "grey50"),
    axis.ticks.x = element_line(color = "grey50"),
    axis.ticks.y = element_blank(),
    axis.text.y = element_text(margin = margin(0, 0, 0, 0))
  )

```
]

.small-font[
Did housing prices in California decline substantially from 1990 to 1998? — yes
]

.small-font[
Did housing prices in West Virginia recover by 2017?  — no
]

???

Figure redrawn after [Claus O. Wilke. Fundamentals of Data Visualization. O'Reilly, 2019.](https://clauswilke.com/dataviz)


---

## Further reading

- Fundamentals of Data Visualization: [Chapter 16: Visualizing uncertainty](https://clauswilke.com/dataviz/visualizing-uncertainty.html)
- L. Padilla, M. Kay, and J. Hullman (2022). [Uncertainty Visualization](
https://osf.io/preprints/psyarxiv/ebd6r)
- J. Hullman, P. Resnick, and E. Adar (2015). [Hypothetical Outcome Plots Outperform Error Bars and Violin Plots for Inferences about Reliability of Variable Ordering](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142444)


